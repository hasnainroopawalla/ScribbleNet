{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Doodle.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "TPwIaPCdLH35"
      ],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hasnainroopawalla/Doodle-Classifier/blob/master/Doodle.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVw_3p-alvaJ",
        "colab_type": "text"
      },
      "source": [
        "**Download the 'classes.txt' file containing all 345 classes\n",
        "OR\n",
        "Download the '100_classes.txt' containing 100 classes**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2Q1QFIYDJWE",
        "colab_type": "code",
        "outputId": "233e35e6-461e-49d4-bda7-044a556be757",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "#!wget 'https://raw.githubusercontent.com/hasnainroopawalla/Doodle-Classifier/master/all_classes.txt'\n",
        "!wget 'https://raw.githubusercontent.com/hasnainroopawalla/Doodle-Classifier/master/100_classes.txt'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-01-13 17:20:17--  https://raw.githubusercontent.com/hasnainroopawalla/Doodle-Classifier/master/100_classes.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 760 [text/plain]\n",
            "Saving to: ‘100_classes.txt’\n",
            "\n",
            "100_classes.txt     100%[===================>]     760  --.-KB/s    in 0s      \n",
            "\n",
            "2020-01-13 17:20:22 (210 MB/s) - ‘100_classes.txt’ saved [760/760]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IAKpXQNDkMB",
        "colab_type": "code",
        "outputId": "5f8cfbf8-5d5b-48a8-946d-b370b3f869ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#f = open(\"all_classes.txt\",\"r\")\n",
        "f = open(\"100_classes.txt\",\"r\")\n",
        "classes = f.readlines()\n",
        "f.close()\n",
        "classes = [c.replace('\\n','').replace(' ','_') for c in classes]\n",
        "print(classes)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['saw', 'coffee_cup', 'power_outlet', 'microphone', 'triangle', 'cat', 'paper_clip', 'drums', 'diving_board', 'sun', 'scissors', 'butterfly', 'ladder', 'beard', 'helmet', 'bicycle', 'face', 'eye', 'syringe', 'bed', 'smiley_face', 'sword', 'door', 'spider', 'bridge', 'spoon', 'fan', 'cell_phone', 'donut', 'rifle', 'baseball_bat', 'camera', 'baseball', 'screwdriver', 'table', 'anvil', 'frying_pan', 'tree', 'chair', 'tooth', 'rainbow', 'bench', 'star', 'ceiling_fan', 'headphones', 'moon', 'key', 'eyeglasses', 'lollipop', 'cookie', 'hat', 'shorts', 'grapes', 'pencil', 'hot_dog', 'bird', 'basketball', 'hammer', 'radio', 't-shirt', 'pizza', 'shovel', 'flower', 'clock', 'wristwatch', 'tent', 'ice_cream', 'airplane', 'mushroom', 'wheel', 'bread', 'mountain', 'axe', 'stop_sign', 'lightning', 'car', 'laptop', 'snake', 'dumbbell', 'sock', 'cup', 'moustache', 'book', 'traffic_light', 'umbrella', 'line', 'suitcase', 'circle', 'candle', 'pants', 'tennis_racquet', 'alarm_clock', 'square', 'pillow', 'cloud', 'broom', 'knife', 'light_bulb', 'apple', 'envelope']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhFbpgqRmHEO",
        "colab_type": "text"
      },
      "source": [
        "**Create a folder called 'data' to store all dataset images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rakGyTcdDxcb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMDXNrnLnw2A",
        "colab_type": "text"
      },
      "source": [
        "**Download images for 345 (or 100) classes and store it in the 'data' folder**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aQgqKd2D0Hj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import urllib.request\n",
        "base = 'https://storage.googleapis.com/quickdraw_dataset/full/numpy_bitmap/'\n",
        "class_num = 0\n",
        "for c in classes:\n",
        "  class_num +=1\n",
        "  print(class_num,c)\n",
        "  cls_url = c.replace('_', '%20')\n",
        "  path = base+cls_url+'.npy'\n",
        "  urllib.request.urlretrieve(path, 'data/'+c+'.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syYT7OA2nsdg",
        "colab_type": "text"
      },
      "source": [
        "**Import all necessary packages**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKBk5_uRFGdU",
        "colab_type": "code",
        "outputId": "b2e1d23f-5240-4e72-ef30-31ecc10f6eab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras \n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from random import randint\n",
        "import tensorflow as tf\n",
        "from PIL import Image, ImageOps\n",
        "import cv2\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.preprocessing.image import load_img"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwqAP2aWq-DH",
        "colab_type": "text"
      },
      "source": [
        "**Select 4000 (or any number) random images for each class and split data into train and test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FC8QuIMFH2p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(root, vfold_ratio=0.2, max_items_per_class = 16000):\n",
        "    all_files = glob.glob(os.path.join(root, '*.npy'))\n",
        "\n",
        "    #initialize variables \n",
        "    x = np.empty([0, 784])\n",
        "    y = np.empty([0])\n",
        "    class_names = []\n",
        "\n",
        "    #load each data file \n",
        "    for idx, file in enumerate(all_files):\n",
        "        data = np.load(file)\n",
        "        data = data[0: max_items_per_class, :]\n",
        "        labels = np.full(data.shape[0], idx)\n",
        "\n",
        "        x = np.concatenate((x, data), axis=0)\n",
        "        y = np.append(y, labels)\n",
        "\n",
        "        class_name, ext = os.path.splitext(os.path.basename(file))\n",
        "        class_names.append(class_name)\n",
        "        print(len(class_names))\n",
        "\n",
        "    data = None\n",
        "    labels = None\n",
        "    \n",
        "    ## Randomize dataset \n",
        "    permutation = np.random.permutation(y.shape[0])\n",
        "    x = x[permutation, :]\n",
        "    y = y[permutation]\n",
        "\n",
        "    #Split dataset into train and test\n",
        "    vfold_size = int(x.shape[0]/100*(vfold_ratio*100))\n",
        "\n",
        "    x_test = x[0:vfold_size, :]\n",
        "    y_test = y[0:vfold_size]\n",
        "\n",
        "    x_train = x[vfold_size:x.shape[0], :]\n",
        "    y_train = y[vfold_size:y.shape[0]]\n",
        "    return x_train, y_train, x_test, y_test, class_names"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSy1Fzs_FQd7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, y_train, x_test, y_test, class_names = load_data('data')\n",
        "num_classes = len(class_names)\n",
        "image_size = 28"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vn9dvz_VrK51",
        "colab_type": "text"
      },
      "source": [
        "**Print number of classes and train images**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iN0vgz3gGiwV",
        "colab_type": "code",
        "outputId": "21c8d361-175a-42db-de3d-caf80c51042a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print('Number of Classes:',num_classes)\n",
        "print('Train Images:',len(x_train))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Classes: 100\n",
            "Train Images: 1280000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjuKDVNwrtV5",
        "colab_type": "text"
      },
      "source": [
        "**Print random image (and its class) from training set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kc_0-oiWGxDg",
        "colab_type": "code",
        "outputId": "9b135fbc-63a6-4294-b2b0-0207eb600b50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "%matplotlib inline  \n",
        "idx = randint(0, len(x_train))\n",
        "plt.imshow(x_train[idx].reshape(28,28)) \n",
        "print(class_names[int(y_train[idx].item())])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "donut\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdXwziDSr6ip",
        "colab_type": "text"
      },
      "source": [
        "**Reshape and normalize each train and test image to 28x28 if not already**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8TYoWVTG4WY",
        "colab_type": "code",
        "outputId": "19a4cce1-cb23-4b61-f5ec-7268599f9c47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "image_size = 28\n",
        "x_train = x_train.reshape(x_train.shape[0], image_size, image_size, 1).astype('float32')\n",
        "x_test = x_test.reshape(x_test.shape[0], image_size, image_size, 1).astype('float32')\n",
        "\n",
        "x_train /= 255.0\n",
        "x_test /= 255.0\n",
        "\n",
        "# Convert class vectors to class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "print(x_train.shape[1:])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXqwoZVqsBn7",
        "colab_type": "text"
      },
      "source": [
        "**Define Model Architecture**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PCPYXLZ_G6V2",
        "colab_type": "code",
        "outputId": "b088900e-cde0-409a-eadd-622f81625ef3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "model = keras.Sequential()\n",
        "model.add(layers.Convolution2D(16, (3, 3),\n",
        "                        padding='same',\n",
        "                        input_shape=x_train.shape[1:], activation='relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Convolution2D(32, (3, 3), padding='same', activation= 'relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(layers.Convolution2D(64, (3, 3), padding='same', activation= 'relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size =(2,2)))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dense(100, activation='softmax'))  # The number here should be equal to number of classes\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(lr=0.001)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['top_k_categorical_accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_3 (Conv2D)            (None, 28, 28, 16)        160       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 14, 14, 16)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 14, 14, 32)        4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 32)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 7, 7, 64)          18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 3, 3, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 576)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               73856     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 100)               12900     \n",
            "=================================================================\n",
            "Total params: 110,052\n",
            "Trainable params: 110,052\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gdotnt7vsJCf",
        "colab_type": "text"
      },
      "source": [
        "**Train the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lIIFyYZbG81y",
        "colab_type": "code",
        "outputId": "5d88425d-1b5e-4440-aaf0-5c2370cfe502",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "model.fit(x = x_train, y = y_train, validation_split=0.1, batch_size = 256, verbose=1, epochs=10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1152000 samples, validate on 128000 samples\n",
            "Epoch 1/10\n",
            "1152000/1152000 [==============================] - 24s 21us/sample - loss: 1.3460 - top_k_categorical_accuracy: 0.8713 - val_loss: 0.9998 - val_top_k_categorical_accuracy: 0.9183\n",
            "Epoch 2/10\n",
            "1152000/1152000 [==============================] - 23s 20us/sample - loss: 0.9162 - top_k_categorical_accuracy: 0.9273 - val_loss: 0.8854 - val_top_k_categorical_accuracy: 0.9292\n",
            "Epoch 3/10\n",
            "1152000/1152000 [==============================] - 23s 20us/sample - loss: 0.8294 - top_k_categorical_accuracy: 0.9352 - val_loss: 0.8247 - val_top_k_categorical_accuracy: 0.9361\n",
            "Epoch 4/10\n",
            "1152000/1152000 [==============================] - 24s 21us/sample - loss: 0.7846 - top_k_categorical_accuracy: 0.9395 - val_loss: 0.7927 - val_top_k_categorical_accuracy: 0.9381\n",
            "Epoch 5/10\n",
            "1152000/1152000 [==============================] - 23s 20us/sample - loss: 0.7553 - top_k_categorical_accuracy: 0.9420 - val_loss: 0.7777 - val_top_k_categorical_accuracy: 0.9396\n",
            "Epoch 6/10\n",
            "1152000/1152000 [==============================] - 23s 20us/sample - loss: 0.7335 - top_k_categorical_accuracy: 0.9441 - val_loss: 0.7520 - val_top_k_categorical_accuracy: 0.9410\n",
            "Epoch 7/10\n",
            "1152000/1152000 [==============================] - 23s 20us/sample - loss: 0.7175 - top_k_categorical_accuracy: 0.9453 - val_loss: 0.7468 - val_top_k_categorical_accuracy: 0.9419\n",
            "Epoch 8/10\n",
            "1152000/1152000 [==============================] - 23s 20us/sample - loss: 0.7049 - top_k_categorical_accuracy: 0.9465 - val_loss: 0.7409 - val_top_k_categorical_accuracy: 0.9427\n",
            "Epoch 9/10\n",
            "1152000/1152000 [==============================] - 23s 20us/sample - loss: 0.6951 - top_k_categorical_accuracy: 0.9473 - val_loss: 0.7416 - val_top_k_categorical_accuracy: 0.9423\n",
            "Epoch 10/10\n",
            "1152000/1152000 [==============================] - 23s 20us/sample - loss: 0.6873 - top_k_categorical_accuracy: 0.9480 - val_loss: 0.7402 - val_top_k_categorical_accuracy: 0.9417\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fdc9c5914a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGz1C7ILHMG2",
        "colab_type": "code",
        "outputId": "ca4a4a26-65ca-460d-efa9-5f05a19c425e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test accuarcy: {:0.2f}%'.format(score[1] * 100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test accuarcy: 94.29%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9kBq83g9WNT",
        "colab_type": "text"
      },
      "source": [
        "**Use random test images to test the model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrKVB4dyHTi_",
        "colab_type": "code",
        "outputId": "44592478-fbe1-46e6-9b20-ef013e6da1be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from random import randint\n",
        "%matplotlib inline  \n",
        "idx = randint(0, len(x_test))\n",
        "img = x_test[idx]\n",
        "plt.imshow(img.squeeze(),cmap='Greys_r') \n",
        "pred = model.predict(np.expand_dims(img, axis=0))[0]\n",
        "ind = (-pred).argsort()[:5]\n",
        "latex = [class_names[x] for x in ind]\n",
        "print(latex)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['sword', 'knife', 'airplane', 'baseball_bat', 'pencil']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wEcKGv8orocEgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wnfDstQYHYKO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('class_names.txt', 'w') as file_handler:\n",
        "    for item in class_names:\n",
        "        file_handler.write(\"{}\\n\".format(item))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0CrQiDcHrvY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('keras.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_8LQwlHCYsz",
        "colab_type": "text"
      },
      "source": [
        "### **Prediction on Input image**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5qnIXp6-Lki",
        "colab_type": "text"
      },
      "source": [
        "**Load the Model and Class Names for predictions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ybfXWETWzLv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.load_model('100_classes_16000_per_class.h5')\n",
        "\n",
        "class_names = ['saw', 'coffee_cup', 'power_outlet', 'microphone', 'triangle', 'cat', 'paper_clip',\n",
        "               'drums', 'diving_board', 'sun', 'scissors', 'butterfly', 'ladder', 'beard', 'helmet',\n",
        "               'bicycle', 'face', 'eye', 'syringe', 'bed', 'smiley_face', 'sword', 'door', 'spider',\n",
        "               'bridge', 'spoon', 'fan', 'cell_phone', 'donut', 'rifle', 'baseball_bat', 'camera', \n",
        "               'baseball', 'screwdriver', 'table', 'anvil', 'frying_pan', 'tree', 'chair', 'tooth',\n",
        "               'rainbow', 'bench', 'star', 'ceiling_fan', 'headphones', 'moon', 'key', 'eyeglasses',\n",
        "               'lollipop', 'cookie', 'hat', 'shorts', 'grapes', 'pencil', 'hot_dog', 'bird', 'basketball',\n",
        "               'hammer', 'radio', 't-shirt', 'pizza', 'shovel', 'flower', 'clock', 'wristwatch', 'tent',\n",
        "               'ice_cream', 'airplane', 'mushroom', 'wheel', 'bread', 'mountain', 'axe', 'stop_sign', \n",
        "               'lightning', 'car', 'laptop', 'snake', 'dumbbell', 'sock', 'cup', 'moustache', 'book', \n",
        "               'traffic_light', 'umbrella', 'line', 'suitcase', 'circle', 'candle', 'pants', 'tennis_racquet',\n",
        "               'alarm_clock', 'square', 'pillow', 'cloud', 'broom', 'knife', 'light_bulb', 'apple', 'envelope']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MzmmBsB-OXh",
        "colab_type": "text"
      },
      "source": [
        "**Make predictions on any input image**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCxKthnCJTcP",
        "colab_type": "code",
        "outputId": "4735dd71-4d98-4120-fd88-7fe9febf090d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "source": [
        "img_path = 'b.png'\n",
        "img = load_img(img_path, target_size=(28,28))\n",
        "img = ImageOps.invert(img)\n",
        "plt.imshow(img) \n",
        "img_tensor = img_to_array(img)\n",
        "\n",
        "plt.imshow(img_tensor/255)\n",
        "\n",
        "img_tensor = cv2.cvtColor(img_tensor, cv2.COLOR_BGR2GRAY) # Convert channel to 1 (grayscale)\n",
        "img_tensor = np.expand_dims(img_tensor, axis=2) # Add last channel as 1  (28,28) to (28,28,1)\n",
        "img_tensor = np.expand_dims(img_tensor, axis=0) # Add 1 more channel at start to specify number of input images (1,28,28,1)\n",
        "img_tensor /= 255. \n",
        "\n",
        "#print(img_tensor.shape)\n",
        "\n",
        "pred = model.predict(img_tensor)[0]\n",
        "ind = (-pred).argsort()[:5]  \n",
        "pred_accuracy = sorted(pred, reverse = True)[:5]  # Accuracy of the top 5 predictions\n",
        "objs = [class_names[x] for x in ind]\n",
        "print(objs)\n",
        "print(pred_accuracy)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['traffic_light', 'key', 'wristwatch', 'bread', 'baseball_bat']\n",
            "[0.99429744, 0.0031828848, 0.00084200146, 0.00044215904, 0.00021474672]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxlhyKEDxaGEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPwIaPCdLH35",
        "colab_type": "text"
      },
      "source": [
        "### **LIME - To interpret the trained model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkvYgcV_I0eQ",
        "colab_type": "code",
        "outputId": "1cc1884c-1e30-441a-97a7-db4d042e8cab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        }
      },
      "source": [
        "!pip install lime\n",
        "import lime \n",
        "from lime import lime_image\n",
        "from skimage.segmentation import mark_boundaries"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting lime\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b5/e0/60070b461a589b2fee0dbc45df9987f150fca83667c2f8a064cef7dbac6b/lime-0.1.1.37.tar.gz (275kB)\n",
            "\r\u001b[K     |█▏                              | 10kB 29.1MB/s eta 0:00:01\r\u001b[K     |██▍                             | 20kB 1.6MB/s eta 0:00:01\r\u001b[K     |███▋                            | 30kB 2.4MB/s eta 0:00:01\r\u001b[K     |████▊                           | 40kB 3.2MB/s eta 0:00:01\r\u001b[K     |██████                          | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 61kB 2.4MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 71kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 81kB 3.2MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 92kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 102kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 112kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 122kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 133kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 143kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 153kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 163kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 174kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 184kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 194kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 204kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 215kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 225kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 235kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 245kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 256kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 266kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 276kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from lime) (1.17.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from lime) (1.4.1)\n",
            "Collecting progressbar\n",
            "  Downloading https://files.pythonhosted.org/packages/a3/a6/b8e451f6cff1c99b4747a2f7235aa904d2d49e8e1464e0b798272aa84358/progressbar-2.5.tar.gz\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.6/dist-packages (from lime) (0.22.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from lime) (3.1.2)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.6/dist-packages (from lime) (0.16.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.18->lime) (0.14.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->lime) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->lime) (2.6.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->lime) (1.1.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->lime) (2.4.6)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.12->lime) (2.4.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.12->lime) (1.1.1)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.12->lime) (6.2.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.12->lime) (2.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib->lime) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->lime) (42.0.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.12->lime) (4.4.1)\n",
            "Building wheels for collected packages: lime, progressbar\n",
            "  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lime: filename=lime-0.1.1.37-cp36-none-any.whl size=284277 sha256=74a2b627850adde3c19067ecbfbefe4c41bbb0b3eb994ad7e144a894f51db87d\n",
            "  Stored in directory: /root/.cache/pip/wheels/c1/38/e7/50d75d4fb75afa604570dc42f20c5c5f5ab26d3fbe8d6ef27b\n",
            "  Building wheel for progressbar (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for progressbar: filename=progressbar-2.5-cp36-none-any.whl size=12073 sha256=61485ce1f4d7c9cfc21ca38e3ba57129d2e99e1e4284445e284b82cf96a8ab7a\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/e9/6b/ea01090205e285175842339aa3b491adeb4015206cda272ff0\n",
            "Successfully built lime progressbar\n",
            "Installing collected packages: progressbar, lime\n",
            "Successfully installed lime-0.1.1.37 progressbar-2.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGbFvZ-kI5aG",
        "colab_type": "code",
        "outputId": "b456ba73-bed5-4a10-a8a2-80655d5ea4c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "source": [
        "img = load_img(img_path, target_size=(28,28))\n",
        "img = img_to_array(img)/255\n",
        "\n",
        "plt.imshow(img)\n",
        "plt.show()\n",
        "\n",
        "#img = np.expand_dims(img, axis=0)\n",
        "print(img.shape)\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "img = np.expand_dims(img, axis=2)\n",
        "print(img.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "(28, 28, 3)\n",
            "(28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_0lGD0gLjZt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "explainer = lime_image.LimeImageExplainer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQuTo8j1Lj0j",
        "colab_type": "code",
        "outputId": "702ecaab-ffb5-4182-df76-ecc3adf93661",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "%%time \n",
        "explanation = explainer.explain_instance(img, model.predict, top_labels=100\n",
        "                                         , hide_color=0, num_samples=1000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-54-d93e79e403d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'explanation = explainer.explain_instance(img, model.predict, top_labels=100\\n                                         , hide_color=0, num_samples=1000)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m</usr/local/lib/python3.6/dist-packages/decorator.py:decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/lime/lime_image.py\u001b[0m in \u001b[0;36mexplain_instance\u001b[0;34m(self, image, classifier_fn, labels, hide_color, top_labels, num_features, num_samples, batch_size, segmentation_fn, distance_metric, model_regressor, random_seed)\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0msegments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msegmentation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0mfudged_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/lime/lime_image.py\u001b[0m in \u001b[0;36mexplain_instance\u001b[0;34m(self, image, classifier_fn, labels, hide_color, top_labels, num_features, num_samples, batch_size, segmentation_fn, distance_metric, model_regressor, random_seed)\u001b[0m\n\u001b[1;32m    179\u001b[0m                                                     random_seed=random_seed)\n\u001b[1;32m    180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0msegments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msegmentation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/lime/wrappers/scikit_image.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/skimage/segmentation/_quickshift.py\u001b[0m in \u001b[0;36mquickshift\u001b[0;34m(image, ratio, kernel_size, max_dist, return_tree, sigma, convert2lab, random_seed)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Only RGB images can be converted to Lab space.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrgb2lab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkernel_size\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/skimage/color/colorconv.py\u001b[0m in \u001b[0;36mrgb2lab\u001b[0;34m(rgb, illuminant, observer)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0msupported\u001b[0m \u001b[0milluminants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m     \"\"\"\n\u001b[0;32m-> 1032\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mxyz2lab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrgb2xyz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrgb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0milluminant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobserver\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/skimage/color/colorconv.py\u001b[0m in \u001b[0;36mrgb2xyz\u001b[0;34m(rgb)\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;31m# Follow the algorithm from http://www.easyrgb.com/index.php\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;31m# except we don't multiply/divide by 100 in the conversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m     \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_prepare_colorarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrgb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m     \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marr\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.04045\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.055\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m1.055\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/skimage/color/colorconv.py\u001b[0m in \u001b[0;36m_prepare_colorarray\u001b[0;34m(arr)\u001b[0m\n\u001b[1;32m    143\u001b[0m         msg = (\"the input array must be have a shape == (.., ..,[ ..,] 3)), \" +\n\u001b[1;32m    144\u001b[0m                \"got (\" + (\", \".join(map(str, arr.shape))) + \")\")\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_as_float\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: the input array must be have a shape == (.., ..,[ ..,] 3)), got (28, 28, 1)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raizSqZFMkFG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Class Order')\n",
        "labels=[print(no+1,class_dict[label]) for no,label in enumerate(explanation.top_labels)]\n",
        "\n",
        "print('For current image instance CNN model has classified Image as: ',class_dict[explanation.top_labels[0]])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSagy1SEMl0j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Expalaning the predection for top class (Class with highest probablity)\n",
        "### change the index of top_labels to see the explanation for other classes \n",
        "### note : Explanation for other classes will  be less informative as the Model has very low probablity (confidence) on those classes\n",
        "temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=True, num_features=4, hide_rest=True)\n",
        "plt.imshow(mark_boundaries(temp,mask))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWXgTM7JMngo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## setting positive_only to False so we get superpixels having positive and negative impact on classification\n",
        "temp, mask = explanation.get_image_and_mask(explanation.top_labels[0], positive_only=False, num_features=4, hide_rest=False)\n",
        "plt.imshow(mark_boundaries(temp,mask))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}